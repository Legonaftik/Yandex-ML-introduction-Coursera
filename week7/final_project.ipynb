{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('./features.csv', index_col='match_id')\n",
    "target = features.radiant_win  # целевая переменная, т.к. мы пытаемся предсказать победителя\n",
    "\n",
    "features = features.drop([\"duration\", \"radiant_win\",  # удаляем признаки, связанные с окончанием игры\n",
    "                          \"tower_status_radiant\",\n",
    "                          \"tower_status_dire\",\n",
    "                         \"barracks_status_radiant\",\n",
    "                          \"barracks_status_dire\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 1: градиентный бустинг \"в лоб\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Найдём признаки, информация о которых имеется не в каждом матче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time\n",
      "first_blood_team\n",
      "first_blood_player1\n",
      "first_blood_player2\n",
      "radiant_bottle_time\n",
      "radiant_courier_time\n",
      "radiant_flying_courier_time\n",
      "radiant_first_ward_time\n",
      "dire_bottle_time\n",
      "dire_courier_time\n",
      "dire_flying_courier_time\n",
      "dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "number_of_matches = features.shape[0]\n",
    "columns_full_check = np.array(features.count() == number_of_matches)\n",
    "not_full = np.array(features.columns[columns_full_check == False])\n",
    "for col in not_full:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки связанные с **\"first_blood\"** имеют пропуски, т.к. в некоторых матчах при довольно аккуратной игре обеих из\n",
    "команд первая кровь может пролиться позднее, чем через 5 минут.\n",
    "\n",
    "Отсутствие **\"bottle\"** объясняется предпочтением закупки отдельных игроков, а также зависит от выбора героев.\n",
    "\n",
    "Что же касается отсутствия **courier**-ов и **ward**-ов, то это прямой признак непрофессионализма игроков. Возможно, речь идёт о матчах\n",
    "с низким приоритетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in not_full:\n",
    "    features[col].fillna(value=0, inplace=True)  # заменяем в этих колонках отсутствующие значения на 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Весь наш анализ проводится с целью как можно точнее научиться предсказывать победителя в матче. А значит, целевой переменной является столбец **\"radiant_win\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество деревьев = 10\n",
      "Кросс-валидация проведена за: 0:00:40.312236\n",
      "Качество: 0.684527487251\n",
      "Количество деревьев = 20\n",
      "Кросс-валидация проведена за: 0:01:21.503651\n",
      "Качество: 0.697243670639\n",
      "Количество деревьев = 30\n",
      "Кросс-валидация проведена за: 0:02:30.854144\n",
      "Качество: 0.702561905698\n",
      "Количество деревьев = 40\n",
      "Кросс-валидация проведена за: 0:02:30.849922\n",
      "Качество: 0.706219091941\n"
     ]
    }
   ],
   "source": [
    "# Далее оценим качество градиентного бустинга с помощью кросс-валидации по 5 блокам\n",
    "kf = KFold(n=number_of_matches, n_folds=5, shuffle=True)\n",
    "for n in [10, 20, 30, 40]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, learning_rate=0.5)  # n_estimators = 10, 20, 30, 40, 60\n",
    "    clf.fit(features, target)\n",
    "    scores = cross_val_score(clf, features, target, cv=kf, scoring=\"roc_auc\")\n",
    "    mean_score = scores.mean()\n",
    "    print(\"Количество деревьев =\", n)\n",
    "    print('Кросс-валидация проведена за:', datetime.datetime.now() - start_time)  # 0:03:19.762472\n",
    "    print(\"Качество:\", mean_score)  # 0.641047001954 (при стандартном max_depth=3 и learning_rate=0.5)\n",
    "\n",
    "#n_estimators= 10\n",
    "# Кросс-валидация проведена за: 0:01:06.490959\n",
    "# 0.684251346261\n",
    "# n_estimators= 20\n",
    "# Кросс-валидация проведена за: 0:02:17.414851\n",
    "# 0.697348323307\n",
    "# n_estimators= 30\n",
    "# Кросс-валидация проведена за: 0:03:22.130787\n",
    "# 0.702367108827\n",
    "# n_estimators= 40\n",
    "# Кросс-валидация проведена за: 0:04:52.590472\n",
    "# 0.70559514774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были проведены тесты при значениях **n_folds**: 10, 20, 30, 40. \n",
    "\n",
    "С увеличением количества деревьев качество градиентного бустинга продолжает расти (максимальное проверенное значение - 40). Для ускорения работы был использован параметр **max_depth** = 2 (однако при ответе на вопрос задания была использована глубина по умолчанию).\n",
    "\n",
    "Следовательно, имеет смысл использовать больше 30 деревьев, особенно при достаточных вычислительных мощностях.\n",
    "\n",
    "Также имеет смысл уменьшить глубину деревьев или ограничиться лишь частью выборки (половиной или даже одной третью при огромных обучающих выборках), чтобы ускорить процесс обучения. Более этого оба этих метода можно совместить, подобрав оптимальные параметры опытным путём. И не стоит забывать, что значительное уменьшение выборки может привести к переобучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "kf = KFold(n=number_of_matches, n_folds=5, shuffle=True)\n",
    "features_scaled = StandardScaler().fit_transform(features)\n",
    "\n",
    "def find_best_param(data, target_col):\n",
    "    global C\n",
    "    grid = {\"C\": np.power(10.0, np.arange(-5, 6))}\n",
    "    clf = LogisticRegression(penalty=\"l2\", C=grid)\n",
    "    gs = GridSearchCV(clf, grid,  scoring=\"roc_auc\", cv=kf)\n",
    "    gs.fit(data, target_col)\n",
    "    C = gs.best_params_[\"C\"]\n",
    "    best_score = gs.best_score_\n",
    "    print(C)\n",
    "    print(best_score)\n",
    "    \n",
    "# find_best_param(features_scaled, target)  # C=0.01, score=0.71641485662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обучим классификатор отдельно для лучшего параметра и замерим время, которое для этого потребуется\n",
    "def logistic_regression(data, target_col, C_best):\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty=\"l2\", C=C_best)\n",
    "    clf.fit(data, target_col)\n",
    "    scores = cross_val_score(clf, data, target_col, cv=kf, scoring=\"roc_auc\")\n",
    "    mean_score = scores.mean()\n",
    "    print(\"Качество:\", mean_score)\n",
    "    print('Кросс-валидация проведена за:', datetime.datetime.now() - start_time)  # 0:00:15.286640\n",
    "    \n",
    "# logistic_regression(features_scaled, target, C)  # 0.71641485662; 0:00:14.681357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Избавимся от категориальных признаков\n",
    "#  lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero\n",
    "features_no_categories = features.drop([\"lobby_type\", \"r1_hero\", \"r2_hero\", \"r3_hero\", \"r4_hero\", \"r5_hero\",\n",
    "                                      \"d1_hero\", \"d2_hero\", \"d3_hero\", \"d4_hero\", \"d5_hero\"], axis=1)\n",
    "features_no_categories = StandardScaler().fit_transform(features_no_categories)\n",
    "\n",
    "# find_best_param(features_no_categories, target)  # C=0.01, 0.716516975892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dd4f7f9347a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Заново применим классификатор с лучшим параметром\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_no_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Качество: 0.716516975892; Время: 0:00:13.347650\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "# Заново применим классификатор с лучшим параметром \n",
    "\n",
    "logistic_regression(features_no_categories, target, C) # Качество: 0.716516975892; Время: 0:00:13.347650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Посчитаем количество уникальных героев\n",
    "match_heroes = ['{}{}_hero'.format(team, order) for team in ['r', 'd'] for order in range(1,6)]\n",
    "hero_IDs = set()\n",
    "for player in match_heroes:\n",
    "    for hero in features[player]:\n",
    "        hero_IDs.add(hero)\n",
    "\n",
    "print(\"Количество уникальных идентификаторов:\", len(hero_IDs))  # 108\n",
    "N = max(hero_IDs)\n",
    "print(\"Максимальный ID\", N)  # 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Добавление мешка слов\n",
    "def calculate_bag_matrix(data, N):\n",
    "    X_pick=np.zeros((data.shape[0], N))\n",
    "    for i, match_id in enumerate(data.index):\n",
    "        for p in range(5):\n",
    "            X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)] - 1] = 1\n",
    "            X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)] - 1] = -1\n",
    "    return X_pick\n",
    "\n",
    "bag = calculate_bag_matrix(features, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Расчёт для данных с мешком слов\n",
    "features_no_categories_bag = np.hstack((features_no_categories, bag))\n",
    "logistic_regression(features_no_categories_bag, target, C)  #0.751734076095; 0:00:20.653868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Приведём к аналогичному виду тестовые данные\n",
    "features_test = pd.read_csv(\"./features_test.csv\", index_col =\"match_id\")\n",
    "\n",
    "number_of_matches = features_test.shape[0]\n",
    "columns_full_check = np.array(features_test.count() == number_of_matches)\n",
    "not_full = np.array(features_test.columns[columns_full_check == False])\n",
    "for col in not_full:\n",
    "    features_test[col].fillna(value=0, inplace=True)  # заменяем в этих колонках отсутствующие значения на 0\n",
    "bag_test = calculate_bag_matrix(features_test, N)\n",
    "features_no_categories_test = features_test.drop([\"lobby_type\", \"r1_hero\", \"r2_hero\", \"r3_hero\", \"r4_hero\", \"r5_hero\",\n",
    "                                      \"d1_hero\", \"d2_hero\", \"d3_hero\", \"d4_hero\", \"d5_hero\"], axis=1)\n",
    "features_no_categories_bag_test = np.hstack((features_no_categories_test, bag_test))\n",
    "features_test_scaled = StandardScaler().fit_transform(features_no_categories_bag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обучим наш лучший классификатор (логистическая регрессия с параметром C=0.01) на всей выборке\n",
    "clf = LogisticRegression(penalty=\"l2\", C=C)\n",
    "clf.fit(features_no_categories_bag, target)\n",
    "\n",
    "# Применим его на тестовых данных\n",
    "pred = clf.predict_proba(features_test_scaled)[:, 1]\n",
    "print(pred.min())  # 8.71766397829e-05\n",
    "print(pred.max())  # 0.999959812711"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
