{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190           26.34s\n",
      "         2           0.9192           25.04s\n",
      "         3           0.8272           23.53s\n",
      "         4           0.7834           22.49s\n",
      "         5           0.7109           22.18s\n",
      "         6           0.6368           22.16s\n",
      "         7           0.5797           21.92s\n",
      "         8           0.5610           21.50s\n",
      "         9           0.5185           21.26s\n",
      "        10           0.4984           22.00s\n",
      "        20           0.1999           20.23s\n",
      "        30           0.1313           18.74s\n",
      "        40           0.0790           17.58s\n",
      "        50           0.0511           16.50s\n",
      "        60           0.0352           15.54s\n",
      "        70           0.0245           14.58s\n",
      "        80           0.0162           13.71s\n",
      "        90           0.0114           13.00s\n",
      "       100           0.0077           12.15s\n",
      "       200           0.0004            3.72s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           23.04s\n",
      "         2           1.0035           23.04s\n",
      "         3           0.9386           23.01s\n",
      "         4           0.8844           22.32s\n",
      "         5           0.8381           21.92s\n",
      "         6           0.7995           21.53s\n",
      "         7           0.7559           21.30s\n",
      "         8           0.7205           21.08s\n",
      "         9           0.6958           20.86s\n",
      "        10           0.6725           20.70s\n",
      "        20           0.4672           18.87s\n",
      "        30           0.3179           18.15s\n",
      "        40           0.2274           17.23s\n",
      "        50           0.1774           16.24s\n",
      "        60           0.1394           15.36s\n",
      "        70           0.1050           14.55s\n",
      "        80           0.0805           13.71s\n",
      "        90           0.0650           12.84s\n",
      "       100           0.0511           12.10s\n",
      "       200           0.0058            4.39s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095           22.40s\n",
      "         2           1.1006           22.33s\n",
      "         3           1.0240           22.36s\n",
      "         4           0.9729           22.18s\n",
      "         5           0.9387           21.50s\n",
      "         6           0.8948           21.48s\n",
      "         7           0.8621           21.15s\n",
      "         8           0.8360           20.81s\n",
      "         9           0.8171           20.78s\n",
      "        10           0.7883           20.70s\n",
      "        20           0.6164           19.44s\n",
      "        30           0.4933           18.34s\n",
      "        40           0.4248           17.18s\n",
      "        50           0.3345           16.32s\n",
      "        60           0.2760           15.41s\n",
      "        70           0.2263           14.73s\n",
      "        80           0.1971           13.79s\n",
      "        90           0.1693           12.96s\n",
      "       100           0.1388           12.31s\n",
      "       200           0.0294            4.41s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           22.34s\n",
      "         2           1.1715           22.27s\n",
      "         3           1.1009           22.24s\n",
      "         4           1.0529           22.47s\n",
      "         5           1.0130           22.27s\n",
      "         6           0.9740           22.35s\n",
      "         7           0.9475           23.12s\n",
      "         8           0.9197           24.01s\n",
      "         9           0.8979           23.73s\n",
      "        10           0.8730           23.41s\n",
      "        20           0.7207           21.84s\n",
      "        30           0.6055           23.51s\n",
      "        40           0.5244           22.57s\n",
      "        50           0.4501           21.95s\n",
      "        60           0.3908           21.06s\n",
      "        70           0.3372           20.62s\n",
      "        80           0.3009           19.91s\n",
      "        90           0.2603           18.73s\n",
      "       100           0.2327           17.65s"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"gbm-data.csv\")\n",
    "data_np = data.as_matrix()\n",
    "features = data_np[:, 1:]\n",
    "target = data_np[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.8, random_state=241)\n",
    "for rate in [1, 0.5, 0.3, 0.2, 0.1]:  # [1, 0.5, 0.3, 0.2, 0.1]\n",
    "    clf = GradientBoostingClassifier(\n",
    "            n_estimators=250, verbose=True, random_state=241, learning_rate=rate)  # \"verbose\" prints out each iteration\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    log_loss_train = []\n",
    "    # staged_decision_function - quality of built composition on each iteration\n",
    "    for pred_train in clf.staged_decision_function(X_train):\n",
    "        log_loss_train.append(log_loss(y_train, 1/(1 + np.exp(-pred_train))))\n",
    "    log_loss_test = []\n",
    "    for pred_test in clf.staged_decision_function(X_test):\n",
    "        log_loss_test.append(log_loss(y_test, 1/(1 + np.exp(-pred_test))))\n",
    "\n",
    "    # plots show us overfittng with increase of iterations\n",
    "    plt.figure()\n",
    "    plt.plot(log_loss_test, \"r\", linewidth=2, label=\"test\")\n",
    "    plt.plot(log_loss_train, \"g\", linewidth=2, label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "log_loss_min = min(log_loss_test)\n",
    "log_loss_min_iter = log_loss_test.index(log_loss_min) + 1\n",
    "print(\"Best quality is\", log_loss_min, \"on the\", str(log_loss_min_iter)+\"-th iteration\")  # 0.530439819735 37\n",
    "\n",
    "# for random forest\n",
    "clf2 = RandomForestClassifier(n_estimators=log_loss_min_iter, random_state=241)\n",
    "clf2.fit(X_train, y_train)\n",
    "pred = clf2.predict_proba(X_test)\n",
    "print(\"For Random Forest quality with the same amount of iterations is:\", log_loss(y_test, pred))  # 0.540911909937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}